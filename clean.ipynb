{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36685eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in file: /u01/mengpengyu/dataPipe\n",
      "Data path: /u01/mengpengyu/dataPipe/data/MatSciInstruct.json\n",
      "None data path: /u01/mengpengyu/dataPipe/data/MatSciInstruct_none.json\n",
      "Total number of data points: 2307\n",
      "Total number of data points with None in 'answer': 471\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json5\n",
    "import os\n",
    "if \"__file__\" not in globals():\n",
    "    __file__ = os.path.abspath(\".\")\n",
    "print(\"Running in file:\", __file__)\n",
    "none_data_path=os.path.join(__file__, 'data','MatSciInstruct_none.json')\n",
    "data_path=os.path.join(__file__,'data', 'MatSciInstruct.json')\n",
    "print(\"Data path:\", data_path)\n",
    "print(\"None data path:\", none_data_path)\n",
    "with open(data_path, 'r') as f:\n",
    "    # Load the JSON5 data from the file\n",
    "    data= json5.load(f)\n",
    "with open(none_data_path, 'r') as f:\n",
    "    # Load the JSON5 data from the file\n",
    "    none_data= json5.load(f)\n",
    "\n",
    "print(\"Total number of data points:\", len(data))\n",
    "print(\"Total number of data points with None in 'answer':\", len(none_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fa5f5",
   "metadata": {},
   "source": [
    "### ç¿»è¯‘éƒ¨åˆ†é—®é¢˜ï¼Œç”¨äºäººå·¥åˆ¤åˆ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deep_translator import BaiduTranslator\n",
    "# import json\n",
    "\n",
    "# # åˆ›å»ºç¿»è¯‘å™¨å¹¶è¿›è¡Œç¿»è¯‘\n",
    "# translator = BaiduTranslator(source='en', \n",
    "#                                   target='zh',\n",
    "#                                   appid=\"20200702000511635\",\n",
    "#                                   appkey='QkuPegRc_zjsNH0Ytn52'\n",
    "#                                   )\n",
    "# # ç¿»è¯‘é—®é¢˜ï¼Œå­˜å‚¨åˆ°ä¸€ä¸ªjsonæ–‡ä»¶ä¸­ï¼Œåç»­æ–¹ä¾¿æŸ¥æ‰¾\n",
    "# translate_path=os.path.join(__file__, 'data','MatSciInstruct_translate.json')\n",
    "# translate_list = []\n",
    "# i=0\n",
    "# for signal_data in data[:200]:\n",
    "#     raw_problem = signal_data['metadata']['instruction']\n",
    "#     translated_problem = translator.translate(raw_problem)\n",
    "#     data_id = signal_data['id']\n",
    "#     translate_list.append({\n",
    "#         \"id\": data_id,\n",
    "#         \"raw_problem\": raw_problem,\n",
    "#         \"translated_problem\": translated_problem\n",
    "#     })\n",
    "#     if i % 10 == 0:\n",
    "#         print(f\"Translated {i} problems\")\n",
    "#     i+=1\n",
    "# print(\"Translated problems:\", translate_list)\n",
    "# with open(translate_path, 'w') as f:\n",
    "#     json.dump(translate_list, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73906027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "  \"id\": \"738abd95be987a0f02e0675d3f3387b1\",\n",
      "  \"category\": \"KNOWLEDGE\",\n",
      "  \"reason\": \"ä¾æ®æ ‡å‡†2.1ï¼Œè¯¥é—®é¢˜è¦æ±‚ä»æä¾›çš„ä¸Šä¸‹æ–‡(inputå­—æ®µ)ä¸­æå–ç ”ç©¶çš„æ¨è®ºï¼Œç­”æ¡ˆå¯ç›´æ¥ä»åŸæ–‡ä¸­æ‰¾åˆ°ã€‚\"\n",
      "}\n",
      "raw problem: What is the corollary of the study?\n",
      "translated problem: è¿™é¡¹ç ”ç©¶çš„æ¨è®ºæ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "\n",
      "\n",
      "{\n",
      "  \"id\": \"5c65bef00762816a5d9de9ecf98b3bf2\",\n",
      "  \"category\": \"KNOWLEDGE\",\n",
      "  \"reason\": \"ä¾æ®æ ‡å‡†2.1ï¼Œç­”æ¡ˆå¯ä»¥ç›´æ¥ä»æä¾›çš„ä¸Šä¸‹æ–‡(inputå­—æ®µ)ä¸­æå–æ‰¾åˆ°å…³äºx=0.2æ—¶Euä»·æ€çš„å…·ä½“æè¿°ã€‚\"\n",
      "}\n",
      "raw problem: What is the valence of Eu in EuPd$_2$(Si$_{1-x}$Ge$_x$)$_2$ for x = 0.2?\n",
      "translated problem: å½“x=0.2æ—¶ï¼ŒEuPd$_2$ï¼ˆSi$_{1-x}$Ge$_x$ï¼‰$_2$ä¸­Euçš„åŒ–åˆä»·æ˜¯å¤šå°‘ï¼Ÿ\n",
      "\n",
      "\n",
      "{\n",
      "  \"id\": \"f744adc51d773be28622ac121c2519b7\",\n",
      "  \"category\": \"REASONING\",\n",
      "  \"reason\": \"ä¾æ®æ ‡å‡†3.1ï¼Œè¯¥é—®é¢˜è¦æ±‚å¯¹è¯ç‰©å‘ç°è¿‡ç¨‹çš„å¤šä¸ªé˜¶æ®µè¿›è¡Œç»„ç»‡å’Œå½’çº³ï¼Œå½¢æˆè¿è´¯çš„æ¦‚è¿°ï¼Œéœ€è¦å¯¹ä¿¡æ¯è¿›è¡Œå¤„ç†å’Œç»„ç»‡ã€‚\"\n",
      "}\n",
      "raw problem: Write a brief overview of the drug discovery process.\n",
      "translated problem: ç®€è¦æ¦‚è¿°è¯ç‰©å‘ç°è¿‡ç¨‹ã€‚\n",
      "\n",
      "\n",
      "{\n",
      "  \"id\": \"fb09b712b74a13f2fcae4405e22084fe\",\n",
      "  \"category\": \"KNOWLEDGE\",\n",
      "  \"reason\": \"ä¾æ®æ ‡å‡†2.1ï¼Œè¯¥é—®é¢˜è¦æ±‚ä»æä¾›çš„ä¸Šä¸‹æ–‡(inputå­—æ®µ)ä¸­æå–å¼•å…¥å­ç³»ç»ŸArfä¸å˜é‡çš„åŠ¨æœºï¼Œç­”æ¡ˆå¯ç›´æ¥æ¦‚æ‹¬å¾—å‡ºã€‚\"\n",
      "}\n",
      "raw problem: What is the motivation for introducing the subsystem Arf invariant?\n",
      "translated problem: å¼•å…¥å­ç³»ç»ŸArfä¸å˜é‡çš„åŠ¨æœºæ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "\n",
      "\n",
      "{\n",
      "  \"id\": \"e0ec17710f199f876c5b553f18ba2134\",\n",
      "  \"category\": \"KNOWLEDGE\",\n",
      "  \"reason\": \"ä¾æ®æ ‡å‡†2.1ï¼Œç­”æ¡ˆå¯ä»¥ç›´æ¥ä»æä¾›çš„ä¸Šä¸‹æ–‡(inputå­—æ®µ)ä¸­æå–æ‰¾åˆ°ï¼Œå³è¾“å…¥ä¸­æ˜ç¡®æåˆ°çš„ä¸‰ä¸ªä¸å˜é‡ï¼šç›¸å…³ç»´æ•°(ğ’Ÿ)ã€ç›¸å…³ç†µ(ğ’¦)å’Œç›¸å…³é›†ä¸­åº¦(ğ’œ)ã€‚\"\n",
      "}\n",
      "raw problem: What are the three invariants that determine the scaling behaviour of the system's R\\'{e}nyi-type extended entropy?\n",
      "translated problem: å†³å®šç³»ç»ŸRçš„ç¼©æ”¾è¡Œä¸ºçš„ä¸‰ä¸ªä¸å˜é‡æ˜¯ä»€ä¹ˆ{e}nyi-typeæ‰©å±•ç†µï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# data[0:10]\n",
    "translate_path=os.path.join(__file__, 'data','MatSciInstruct_translate.json')\n",
    "with open(translate_path, 'r') as f:\n",
    "    # Load the JSON5 data from the file\n",
    "    translate_data= json5.load(f)\n",
    "from model import call_openai,call_huoshan\n",
    "prompt_path=os.path.join(__file__, 'prompts','division.txt')\n",
    "with open(prompt_path, 'r') as f:\n",
    "    raw_prompt = f.read()\n",
    "end=5\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "for signal_data, trans_problem in zip(data[0:end], translate_data[0:end]):\n",
    "    data_id = signal_data['id']\n",
    "    input_data = {key: signal_data[key] for key in ['id', 'metadata']}\n",
    "    prompt = raw_prompt.replace(\"{}\",str(input_data))\n",
    "    _ ,content=call_huoshan(prompt,'doubao')\n",
    "    print(content)\n",
    "    print(f\"raw problem: {trans_problem['raw_problem']}\")\n",
    "    print(f\"translated problem: {trans_problem['translated_problem']}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
